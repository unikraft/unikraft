# inference_lb -- inference with large batch size
--mb=640
--alg=VANILLA_LSTM
--activation=TANH
--batch=rnn_gnmt_decoder

--mb=64
--alg=VANILLA_LSTM
--activation=TANH
--batch=rnn_gnmt_encoder

--mb=64
--alg=VANILLA_RNN
--batch=rnn_ds2

--mb=64
--alg=LBR_GRU
--batch=rnn_ds2
